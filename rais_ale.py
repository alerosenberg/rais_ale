# -*- coding: utf-8 -*-
"""RAIS_ALE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KT6ipWkDwKMradAGtex87rQwanw4u6HE
"""

import sys

PERGUNTA = "Você gostaria de deletar os dados não processados da RAIS do seu computador?"

def query_yes_no(question, default="no"):
    """Ask a yes/no question via input() and return their answer.
    "question" is a string that is presented to the user.
    "default" is the presumed answer if the user just hits <Enter>.
        It must be "yes" (the default), "no" or None (meaning
        an answer is required of the user).
    The "answer" return value is True for "yes" or False for "no".
    """
    valid = {"yes": True, "y": True, "ye": True,
             "no": False, "n": False}
    if default is None:
        prompt = " [y/n] "
    elif default == "yes":
        prompt = " [Y/n] "
    elif default == "no":
        prompt = " [y/N] "
    else:
        raise ValueError("invalid default answer: '%s'" % default)

    while True:
        sys.stdout.write(question + prompt)
        choice = input().lower()
        if default is not None and choice == '':
            return valid[default]
        elif choice in valid:
            return valid[choice]
        else:
            sys.stdout.write("Please respond with 'yes' or 'no' "
                             "(or 'y' or 'n').\n")

pip install wget

import wget

from tqdm import tqdm

pip install dask

import dask

pip install dask[dataframe]

import dask.dataframe as dd

import pandas as pd

import os

urls = [
    #2018
    #"ftp://ftp.mtps.gov.br/pdet/microdados/RAIS/2018/RAIS_VINC_PUB_SP.7z",
    #2017
    #"ftp://ftp.mtps.gov.br/pdet/microdados/RAIS/2017/SP2017.7z",
    #2016
    #"ftp://ftp.mtps.gov.br/pdet/microdados/RAIS/2016/SP2016.7z",
    #2015
    #"ftp://ftp.mtps.gov.br/pdet/microdados/RAIS/2015/SP2015.7z",
    #2014
    #"ftp://ftp.mtps.gov.br/pdet/microdados/RAIS/2014/SP2014.7z",
    #2013
    #"ftp://ftp.mtps.gov.br/pdet/microdados/RAIS/2013/SP2013.7z",
    #2012
    #"ftp://ftp.mtps.gov.br/pdet/microdados/RAIS/2012/SP2012.7z",
    #2011
    #"ftp://ftp.mtps.gov.br/pdet/microdados/RAIS/2011/SP2011.7z",
    #2010
    #"ftp://ftp.mtps.gov.br/pdet/microdados/RAIS/2010/SP2010.7z",
    #2009
    #"ftp://ftp.mtps.gov.br/pdet/microdados/RAIS/2009/SP2009.7z",
    #2008
    "ftp://ftp.mtps.gov.br/pdet/microdados/RAIS/2008/SP2008.7z"
]

def importa_filtra(url):
    filename = wget.download(url,out="C:/Users/Ale/Desktop/Dissertação/RAIS/Diretorio")
    archive = py7zr.SevenZipFile(filename)
    archive.extractall(path="C:/Users/Ale/Desktop/Dissertação/RAIS/Diretorio")
    archive.close()
    os.remove(filename)
    file = filename[:-2] + "txt"
    if url == "ftp://ftp.mtps.gov.br/pdet/microdados/RAIS/2008/SP2008.7z":
        df = dd.read_csv(file, sep=';', encoding="latin1", assume_missing=True,
                        dtype={'CBO Ocupação 2002': 'object',
                                'Faixa Remun Dezem (SM)': 'object',
                                'Faixa Tempo Emprego': 'object',
                                'Faixa Etária': 'object',
                                'Bairros SP': 'object',
                                'Distritos SP': 'object',
                                'Bairros RJ': 'object',
                                'Raça Cor': 'object',
                                'Natureza Jurídica': 'object',
                                'CNAE 2.0 Subclasse': 'object',
                                'Tipo Defic': 'object',
                                'CNAE 2.0 Classe': 'object',
                                'CNAE 95 Classe': 'object'})
        df['CNAE 2.0 Classe'] = df['CNAE 2.0 Classe'].apply(pd.to_numeric, errors='coerce')
    else:
        df = dd.read_csv(file, sep=';', encoding="latin1", assume_missing=True,
                        dtype={'CBO Ocupação 2002': 'object',
                                'Faixa Remun Dezem (SM)': 'object',
                                'Faixa Tempo Emprego': 'object',
                                'Faixa Etária': 'object',
                                'Bairros SP': 'object',
                                'Distritos SP': 'object',
                                'Bairros RJ': 'object',
                                'Raça Cor': 'object',
                                'Natureza Jurídica': 'object',
                                'CNAE 2.0 Subclasse': 'object',
                                'Tipo Defic': 'object'})
    df = df.loc[(df["CNAE 2.0 Classe"] >= 62000) & (df["CNAE 2.0 Classe"] < 62050) ,:]
    computed_df = df.compute()
    computed_df.to_csv("C:/Users/Ale/Desktop/Dissertação/RAIS/Diretorio" + file[13:-3] + "csv", sep="\t", index=False)
    os.remove(file)

def obter_dados():
    for url in tqdm(urls):
        importa_filtra(url)

    obter_dados()

pip install utils

import utils

import sys

import glob
import pandas as pd
import numpy as np

from datetime import datetime

import re

# Exporta os dados
    pd.concat(limpos, sort=False)[[
        'Ano', 'CNAE 2.0 Classe', 
       'Escolaridade após 2005', 'Qtd Hora Contr', 'Idade',
       'Ind Simples',
       'Mun Trab', 'Município', 'Nacionalidade','Brasileiro', 'Natureza Jurídica',
       'Ind Portador Defic', 'Qtd Dias Afastamento', 'Raça Cor',
       'Regiões Adm DF', 'Vl Remun Dezembro Nom', 'Vl Remun Dezembro (SM)',
       'Vl Remun Média Nom', 'Vl Remun Média (SM)', 'CNAE 2.0 Subclasse',
       'Sexo Trabalhador', 'Tamanho Estabelecimento', 'Tempo Emprego',
       'Tipo Admissão', 'Tipo Defic', 'Tipo Salário',
       'Tipo Vínculo']].to_csv("C:/Users/Ale/Desktop/Dissertação/RAIS/Diretorio/rais_2008.csv", sep='\t', index=False)









